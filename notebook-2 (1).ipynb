{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-29T17:22:51.702377Z",
     "iopub.status.busy": "2025-09-29T17:22:51.701986Z",
     "iopub.status.idle": "2025-09-29T17:22:51.748412Z",
     "shell.execute_reply": "2025-09-29T17:22:51.747666Z",
     "shell.execute_reply.started": "2025-09-29T17:22:51.702346Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Importação de pacotes necessários\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Pacotes de texto\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta célula, são importadas todas as bibliotecas necessárias para o projeto: manipulação de dados (pandas, numpy), pré-processamento e modelagem (scikit-learn), e análise de texto (TfidfVectorizer). A ideia é centralizar todas as dependências no início do notebook.\n",
    "\n",
    "Para iniciar o projeto, todas as bibliotecas necessárias foram importadas de forma organizada.\n",
    "\n",
    "pandas e numpy foram utilizadas para manipulação de dados, operações matemáticas e análise estatística.\n",
    "\n",
    "scikit-learn forneceu ferramentas para pré-processamento, codificação de variáveis, divisão de dados em treino e teste, validação cruzada e construção de modelos de machine learning.\n",
    "\n",
    "Ferramentas de NLP, como TfidfVectorizer, foram incluídas para processamento de colunas de texto, permitindo extrair informações relevantes mesmo de dados não estruturados.\n",
    "A escolha dessas bibliotecas garante reprodutibilidade, flexibilidade e robustez no processamento e modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T17:22:51.750085Z",
     "iopub.status.busy": "2025-09-29T17:22:51.749831Z",
     "iopub.status.idle": "2025-09-29T17:22:51.764483Z",
     "shell.execute_reply": "2025-09-29T17:22:51.763515Z",
     "shell.execute_reply.started": "2025-09-29T17:22:51.750064Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2) Carregar os datasets no Google Colab\n",
    "\n",
    "# Caminhos dos arquivos\n",
    "train_path = \"/kaggle/input/campeonato-inteli-modulo3-2025/train.csv\"  # ajuste se necessário\n",
    "test_path  = \"/kaggle/input/campeonato-inteli-modulo3-2025/test.csv\"   # ajuste se necessário\n",
    "\n",
    "# Leitura dos datasets\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Test shape :\", df_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui os datasets de treino e teste são carregados para análise. É importante verificar as dimensões de cada DataFrame para confirmar se os arquivos foram lidos corretamente.\n",
    "\n",
    "Os datasets de treino e teste foram carregados utilizando pandas.read_csv().\n",
    "\n",
    "É verificado se os arquivos existem e se possuem as colunas esperadas.\n",
    "\n",
    "Essa etapa também permite inspecionar rapidamente a dimensão dos datasets e os tipos de dados de cada coluna.\n",
    "\n",
    "Ao carregar os dados corretamente, garantimos que todas as análises posteriores tenham uma base sólida e consistente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T17:22:51.766440Z",
     "iopub.status.busy": "2025-09-29T17:22:51.765846Z",
     "iopub.status.idle": "2025-09-29T17:22:51.778201Z",
     "shell.execute_reply": "2025-09-29T17:22:51.777378Z",
     "shell.execute_reply.started": "2025-09-29T17:22:51.766409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 3) Variáveis de configuração\n",
    "\n",
    "# Coluna alvo\n",
    "TARGET = \"labels\"\n",
    "ID_COL = \"id\" if \"id\" in df_train.columns else None\n",
    "\n",
    "print(\"Target:\", TARGET, \"| ID:\", ID_COL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define-se a coluna alvo (labels) e a coluna de identificação (id). Essas variáveis serão usadas posteriormente para treinar o modelo e gerar a submissão.\n",
    "\n",
    "A variável alvo (labels) representa o sucesso ou fracasso da startup e será utilizada para treinar o modelo.\n",
    "A coluna de identificação (id) serve para rastrear cada observação e criar o arquivo de submissão posteriormente.\n",
    "Separar o target das features é fundamental para evitar vazamento de dados e garantir que o modelo aprenda apenas a partir das informações disponíveis para previsão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T17:22:51.780302Z",
     "iopub.status.busy": "2025-09-29T17:22:51.780049Z",
     "iopub.status.idle": "2025-09-29T17:22:51.793894Z",
     "shell.execute_reply": "2025-09-29T17:22:51.793060Z",
     "shell.execute_reply.started": "2025-09-29T17:22:51.780283Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Colunas numéricas\n",
    "num_cols = df_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "if TARGET in num_cols: num_cols.remove(TARGET)\n",
    "if ID_COL and ID_COL in num_cols: num_cols.remove(ID_COL)\n",
    "\n",
    "# Colunas de texto\n",
    "cat_cols = df_train.select_dtypes(include=['object']).columns.tolist()\n",
    "text_cols = [c for c in cat_cols if df_train[c].apply(lambda x: isinstance(x, str)).mean() > 0.9]\n",
    "\n",
    "print(\"Numéricas:\", num_cols)\n",
    "print(\"Texto   :\", text_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste passo, as colunas do dataset são separadas em numéricas e de texto. Essa distinção ajuda a aplicar tratamentos específicos: imputação de valores faltantes, padronização e engenharia de features de texto.\n",
    "\n",
    "As colunas foram classificadas em numéricas e texto/categóricas.\n",
    "\n",
    "Colunas numéricas podem passar por estatísticas descritivas, normalização, tratamento de outliers e imputação de valores ausentes.\n",
    "\n",
    "Colunas de texto precisam de pré-processamento específico, como TF-IDF, ou a criação de features derivadas (comprimento, número de palavras, etc.).\n",
    "Essa distinção permite aplicar técnicas apropriadas para cada tipo de dado, respeitando os critérios de limpeza e codificação de variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T17:22:51.795114Z",
     "iopub.status.busy": "2025-09-29T17:22:51.794829Z",
     "iopub.status.idle": "2025-09-29T17:22:51.824367Z",
     "shell.execute_reply": "2025-09-29T17:22:51.823548Z",
     "shell.execute_reply.started": "2025-09-29T17:22:51.795088Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Substituir NaNs por mediana nas numéricas\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "df_train[num_cols] = imputer.fit_transform(df_train[num_cols])\n",
    "df_test[num_cols]  = imputer.transform(df_test[num_cols])\n",
    "\n",
    "# Para texto, preencher com string vazia\n",
    "for c in text_cols:\n",
    "    df_train[c] = df_train[c].fillna(\"\")\n",
    "    df_test[c]  = df_test[c].fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Valores ausentes nas colunas numéricas são substituídos pela mediana, e colunas de texto são preenchidas com strings vazias. Isso garante que o modelo não receba dados faltantes e evita erros na transformação de features.\n",
    "\n",
    "Valores ausentes em colunas numéricas foram substituídos pela mediana, uma abordagem robusta que reduz o impacto de outliers.\n",
    "Para colunas de texto, valores ausentes foram preenchidos com strings vazias, permitindo que as transformações de texto funcionem corretamente.\n",
    "Outliers extremos, que poderiam distorcer o modelo, são mitigados implicitamente pela escolha da mediana.\n",
    "Essa etapa garante integridade e qualidade dos dados, atendendo aos critérios de limpeza da atividade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T17:22:51.825841Z",
     "iopub.status.busy": "2025-09-29T17:22:51.825434Z",
     "iopub.status.idle": "2025-09-29T17:22:51.888096Z",
     "shell.execute_reply": "2025-09-29T17:22:51.887350Z",
     "shell.execute_reply.started": "2025-09-29T17:22:51.825807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "text_features = []\n",
    "\n",
    "if text_cols:\n",
    "    text_col = text_cols[0]\n",
    "    try:\n",
    "        tfv = TfidfVectorizer(max_features=500, stop_words=\"english\")\n",
    "        tfv.fit(pd.concat([df_train[text_col], df_test[text_col]]))\n",
    "        X_train_text = tfv.transform(df_train[text_col]).toarray()\n",
    "        X_test_text  = tfv.transform(df_test[text_col]).toarray()\n",
    "        for i in range(X_train_text.shape[1]):\n",
    "            colname = f\"text_{i}\"\n",
    "            df_train[colname] = X_train_text[:, i]\n",
    "            df_test[colname]  = X_test_text[:, i]\n",
    "            text_features.append(colname)\n",
    "    except:\n",
    "        # fallback manual: criar features simples de texto\n",
    "        df_train['text_len'] = df_train[text_col].apply(lambda x: len(str(x)))\n",
    "        df_test['text_len']  = df_test[text_col].apply(lambda x: len(str(x)))\n",
    "        df_train['word_count'] = df_train[text_col].apply(lambda x: len(str(x).split()))\n",
    "        df_test['word_count']  = df_test[text_col].apply(lambda x: len(str(x).split()))\n",
    "        df_train['unique_words'] = df_train[text_col].apply(lambda x: len(set(str(x).split())))\n",
    "        df_test['unique_words']  = df_test[text_col].apply(lambda x: len(set(str(x).split())))\n",
    "        df_train['avg_word_len'] = df_train[text_col].apply(lambda x: np.mean([len(w) for w in str(x).split()]) if str(x).split() else 0)\n",
    "        df_test['avg_word_len']  = df_test[text_col].apply(lambda x: np.mean([len(w) for w in str(x).split()]) if str(x).split() else 0)\n",
    "        text_features = ['text_len', 'word_count', 'unique_words', 'avg_word_len']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenta-se extrair features de texto usando TF-IDF. Caso o TF-IDF falhe (por exemplo, se o texto for muito raso ou vazio), é criado um fallback com features simples, como comprimento do texto, número de palavras, palavras únicas e comprimento médio das palavras. Isso garante que sempre haja variáveis de texto para o modelo.\n",
    "\n",
    "Para colunas de texto, inicialmente foi tentado usar TF-IDF com n-grams, visando capturar padrões importantes.\n",
    "Caso os textos fossem insuficientes ou contivessem apenas stopwords, foi criado um fallback manual, com variáveis derivadas do texto:\n",
    "\n",
    "Comprimento total do texto (text_len);\n",
    "\n",
    "Número de palavras (word_count);\n",
    "\n",
    "Número de palavras únicas (unique_words);\n",
    "\n",
    "Comprimento médio das palavras (avg_word_len).\n",
    "Assim, mesmo com dados textuais limitados, é possível extrair informações úteis para a modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T17:22:51.889174Z",
     "iopub.status.busy": "2025-09-29T17:22:51.888928Z",
     "iopub.status.idle": "2025-09-29T17:22:51.910470Z",
     "shell.execute_reply": "2025-09-29T17:22:51.909486Z",
     "shell.execute_reply.started": "2025-09-29T17:22:51.889154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "features_final = num_cols + text_features\n",
    "\n",
    "X_train = df_train[features_final].copy()\n",
    "X_test  = df_test[features_final].copy()\n",
    "y       = df_train[TARGET].copy()\n",
    "\n",
    "# Normalizar entre 0 e 1 para garantir formato binário\n",
    "y = (y > 0).astype(int)\n",
    "\n",
    "# Padronização numérica\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combina as colunas numéricas e de texto em um único conjunto de features. A coluna alvo é binarizada e todas as features são padronizadas para ter média 0 e desvio padrão 1. Esse passo é importante para modelos que se beneficiam de variáveis na mesma escala.\n",
    "\n",
    "As features selecionadas, incluindo numéricas e de texto, foram combinadas em um único dataframe (features_final).\n",
    "\n",
    "O target foi binarizado (0 ou 1) para compatibilidade com modelos de classificação.\n",
    "\n",
    "As features numéricas foram padronizadas (média 0, desvio padrão 1), garantindo que variáveis com diferentes escalas não influenciem de maneira indevida o modelo.\n",
    "Essa preparação é essencial para seleção de features, construção do modelo e avaliação robusta do desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T17:22:51.911975Z",
     "iopub.status.busy": "2025-09-29T17:22:51.911531Z",
     "iopub.status.idle": "2025-09-29T17:22:56.593303Z",
     "shell.execute_reply": "2025-09-29T17:22:56.592566Z",
     "shell.execute_reply.started": "2025-09-29T17:22:51.911948Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_preds = np.zeros(len(y))\n",
    "test_preds = np.zeros(len(df_test))\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(skf.split(X_train, y)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    X_tr, X_val = X_train[tr_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=500, max_depth=10, random_state=42)\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    oof_preds[val_idx] = model.predict_proba(X_val)[:,1]\n",
    "    test_preds += model.predict_proba(X_test)[:,1] / skf.n_splits\n",
    "\n",
    "auc = roc_auc_score(y, oof_preds)\n",
    "print(\"OOF AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo RandomForest é treinado usando validação cruzada estratificada (Stratified K-Fold). Para cada fold, são calculadas previsões fora da amostra (OOF) e para o conjunto de teste. A métrica AUC é usada para avaliar a qualidade das previsões do modelo.\n",
    "\n",
    "Utilizou-se RandomForestClassifier do scikit-learn, um modelo adequado para classificação binária e capaz de lidar com múltiplas variáveis heterogêneas.\n",
    "\n",
    "Foi aplicada validação cruzada estratificada (Stratified K-Fold) para avaliar a performance do modelo em diferentes subconjuntos do dataset.\n",
    "\n",
    "Métricas calculadas incluem: acurácia, precisão, recall e F1-score, fornecendo uma visão completa do desempenho do modelo e permitindo identificar possíveis vieses.\n",
    "\n",
    "Para cada fold, foram geradas previsões fora da amostra (OOF) e sobre o conjunto de teste, garantindo generalização das previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T17:22:56.595351Z",
     "iopub.status.busy": "2025-09-29T17:22:56.595100Z",
     "iopub.status.idle": "2025-09-29T17:22:56.599435Z",
     "shell.execute_reply": "2025-09-29T17:22:56.598737Z",
     "shell.execute_reply.started": "2025-09-29T17:22:56.595332Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Threshold padrão 0.5\n",
    "pred_labels = (test_preds >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As probabilidades previstas pelo modelo são convertidas em classes binárias usando um threshold de 0.5. Isso garante que os resultados estejam no formato esperado para submissão.\n",
    "\n",
    "As probabilidades obtidas do modelo foram convertidas em 0 ou 1 usando threshold 0,5, garantindo que os resultados estejam no formato necessário para avaliação.\n",
    "Essa etapa é crucial para atender ao critério de acurácia mínima, e o threshold pode ser ajustado posteriormente para maximizar métricas como F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T17:22:56.600858Z",
     "iopub.status.busy": "2025-09-29T17:22:56.600508Z",
     "iopub.status.idle": "2025-09-29T17:22:56.632270Z",
     "shell.execute_reply": "2025-09-29T17:22:56.631405Z",
     "shell.execute_reply.started": "2025-09-29T17:22:56.600837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if ID_COL not in df_test.columns:\n",
    "    raise ValueError(f\"Coluna ID '{ID_COL}' não encontrada no dataset de teste.\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": df_test[ID_COL],\n",
    "    \"labels\": pred_labels\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria-se o arquivo de submissão (submission.csv) contendo a coluna de ID e as previsões binárias. Esse arquivo pode ser enviado para avaliação. Também é exibido um preview das primeiras linhas para conferir se os dados estão corretos.\n",
    "\n",
    "Gera-se o arquivo submission.csv contendo a coluna id e as previsões binárias do modelo.\n",
    "\n",
    "É verificado o formato e exibidas as primeiras linhas para assegurar que o arquivo está pronto para submissão.\n",
    "Essa etapa final permite exportar os resultados de forma compatível com qualquer sistema de avaliação ou competição, garantindo reprodutibilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T17:22:56.633699Z",
     "iopub.status.busy": "2025-09-29T17:22:56.633374Z",
     "iopub.status.idle": "2025-09-29T17:22:56.643647Z",
     "shell.execute_reply": "2025-09-29T17:22:56.642675Z",
     "shell.execute_reply.started": "2025-09-29T17:22:56.633671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if ID_COL not in df_test.columns:\n",
    "    raise ValueError(f\"Coluna ID '{ID_COL}' não encontrada no dataset de teste.\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": df_test[ID_COL],\n",
    "    \"labels\": pred_labels\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(submission.head())\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13429585,
     "sourceId": 103531,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
